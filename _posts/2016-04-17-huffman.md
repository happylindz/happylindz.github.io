---
layout:     post
title:      "数据结构 - 哈夫曼树"
date:       2016-04-17 12:00:00
author:     "Lindz"
header-img: "img/3.jpg"
tags:
    - 数据结构
---

## (一) 前言

例如：我们要将一个百分制的考试成绩转换为五分制的成绩，我们很容易写出这样的代码。

```java
if(score < 60) grade = 1;
else if(score >=60 && score < 70) grade = 2;
else if (score >= 70 && score < 80) grade = 3;
else if(score >= 80 && score < 90) grade = 4;
else grade = 5;
```

但是实际情况是绝大多数人的分数都在 80~90分的范围内，那么绝大多数都需要经过 4 次判断才能得出结论，这显然是非常耗时的，不够优化。

如果考虑学生成绩的分布概率如下： 

| 分数段 | 0-59 | 60-69 | 70-79 | 80-89 | 90 - 100 |
| :--: |:----:| :-----:| :----: |:----:|:----:|
| 比例   | 0.05 | 0.15  | 0.40  | 0.30  | 0.10  |

则刚才的代码的查找效率就为:

```0.05 * 1 + 0.15 * 2 + 0.4 * 3 + 0.3 * 4 + 0.1 * 4 =  3.15```

再比如说，我们常常用 ASCII 来表示英文单词，而每个英文单词需要 8 个位，但是有一些单词比如 e, a, t, n 被经常使用，而 q, x, y, z 并不经常使用。如果我们能够缩短经常使用的字母的编码，那么将会大大空间的利用。

## (二) 基本概念 (Huffman Tree)：

### 路径和路径长度:

在一棵树中，从一个结点往下可以达到的孩子或孙子结点之间的通路，称为路径。通路中分支的数目称为路径长度。若规定根结点的层数为 1，则从根结点到第L层结点的路径长哈夫曼树度为 L-1。

### 结点的权及带权路径长度:

若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。结点的带权路径长度为：从根结点到该结点之间的路径长度与该结点的权的乘积。

### 树的带权路径长度:

树的带权路径长度规定为所有叶子结点的带权路径长度之和，记为 WPL。即设二叉树有 n 个叶子结点，每个叶子结点带有权值 wk，从根结点到每个叶子的长度为 lk,则每个叶子结点的带权路径长度之和：WPL = ∑wi*li (i = 0,1,2...n)

**哈夫曼树(也称为最优二叉树)就是使 WPL 达到最小的二叉树, 哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。**

### 构造方式：

哈夫曼算法：假设有n个权值，则构造出的哈夫曼树有 n 个叶子结点。 n个权值分别设为 w1、w2、…、wn，则哈夫曼树的构造规则为：

1. 将 w1、w2、…，wn 看成是有 n 棵树的森林(每棵树仅有一个结点)
2. 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和
3. 从森林中删除选取的两棵树，并将新树加入森林
4. 重复步骤 2、3，直到森林中只剩下一棵树为止，该树即为所求的哈夫曼树

例如，给定 4 个权值为 1、3、5、7 的节点构造一棵哈夫曼树，其构造方式如下：

![](/assets/2016-04-17-huffman/1.png)

## (三) 哈夫曼编码 (Huffman Coding)

**哈夫曼编码是哈夫曼树的一个应用。哈夫曼编码又称为霍夫曼编码，哈夫曼编码是可变字长编码 (VLC) 的一种，该方法完全依据字符出现概率来构造异字头的平均长度最短的码字，有时称之为最佳编码，一般就叫做Huffman编码。**

让我们简单地来看一个例子：假设我们有条信息只使用到了字母 a, e, i, s, t, 空格，换行，且假设它们的频率如下

| 字母 | 编码 | 频率 | 位总数 | 
|:--:|:----:|:-----:|:----:|
| a | 000 | 10 | 30 |
| e | 001 | 15 | 45 |
| i | 010 | 12 | 36 |
| s | 011 | 3 | 9 |
| t | 100 | 4 | 12 |
| sp | 101 | 13 | 39 |
| nl | 110 | 1 | 3 |
| 总数 | - | - | 174 |

我们假设：

* 我们将所有的字母都放在二叉树的叶结点上
* 编码的含义：0 代表向左，1 代表向右

则由上面的图我们可以构造出一颗二叉树：

![](/assets/2016-04-17-huffman/2.png)

而如果我们将其改为：

![](/assets/2016-04-17-huffman/3.png)

即 nl 由原来的 110 变为了 11，则花费的位总数就变为了 173。

**虽然我们将 nl 码由原来的三位变为两位，但是只要保证每个字母的编码不会成为其他字母编码的前缀，那么这样的编码就不会引起混淆，这样的编码我们称之为前缀码 (Prefix Code)**

根据前面的构造方法的介绍，首先存储一个每个点树构成的森林集合，每棵树带有它的权值，且只包含一个点，可以如下表示：

![](/assets/2016-04-17-huffman/4.png)

在接下来的每一步处理中，两个权值最小的树合并为一棵树并重新添加回集合中

![](/assets/2016-04-17-huffman/5.png)

最小权值的树为 s 和nl

![](/assets/2016-04-17-huffman/6.png)

此时最小权值的树为 T1 和 t

![](/assets/2016-04-17-huffman/7.png)

就这样一步步构造，最后皆可以生成哈夫曼树。

![](/assets/2016-04-17-huffman/8.png)

根据哈夫曼树，0 代表向左，1代表向右的规则，我们就可以列出新的编码格式

| 字母 | 编码 | 频率 | 位总数 | 
|:--:|:----:|:-----:|:----:|
| a | 001 | 10 | 30 |
| e | 01 | 15 | 30 |
| i | 10 | 12 | 24 |
| s | 00000 | 3 | 15 |
| t | 0001 | 4 | 16 |
| sp | 11 | 13 | 26 |
| nl | 00001 | 1 | 5 |
| 总数 | - | - | 146 |

**现在该信息所需要的编码位数由原来的 174 减少到了 146，大大减少了空间的浪费。**

总结：

* 可以很直观地证明，哈夫曼算法提供了最优的编码方式
* 如果我们将森林集合存储在一个优先队列里面，那么时间复杂度为 O(clogc) c 为字母个数
* 哈夫曼算法是一种贪婪算法，因为它在每一步只是简单从集合中取出两个权值最小的树进行合并

